
[toc]

# 实验：MHA
<img src="https://img-blog.csdnimg.cn/2019071608591665.png" width="70%">

1. 实验环境：
1 台Manager主机：192.168.99.101
1 台Master主机：192.168.99.102
2 台slave主机：192.168.99.103~104
2. 准备2个安装包
`mha4mysql-manager` 和 `mha4mysql-node`

>链接：https://pan.baidu.com/s/1lu0HPQDanJRotSZoVoPlHw 
提取码：pvt4 


<table><td bgcolor=orange> Manager主机：192.168.99.101 </td></table>

1. 在管理节点上安装两个包，注意，yum源需要EPEL
```bash
#先安装这个
[101]$ yum -y localinstall mha4mysql-node
#再安装这个
[101]$ yum -y localinstall mha4mysql-manager
```

<table><td bgcolor=orange> Master主机：192.168.99.102 </td></table>

1. 在被管理节点安装，注意，yum源需要EPEL
```bash
[102]$ yum -y localinstall mha4mysql-node
```

<table><td bgcolor=orange> slave主机：192.168.99.103 </td></table>

1. 在被管理节点安装，注意，yum源需要EPEL
```bash
[103]$ yum -y localinstall mha4mysql-node
```

<table><td bgcolor=orange> 另一个slave主机：192.168.99.104 </td></table>

1. 在被管理节点安装，注意，yum源需要EPEL
```bash
[104]$ yum -y localinstall mha4mysql-node
```

<table><td bgcolor=orange> Manager主机：192.168.99.101 </td></table>

1. 在管理节点建立配置文件
```bash
#新建目录，用于存放配置文件
[101]$ mkdir /etc/mastermha/
#创建mha的工作目录
[101]$ mkdir -p /data/mastermha/app1
#配置文件可能不存在，直接新建
[101]$ vim /etc/mastermha/app1.cnf
    [server default]
    user=mhauser   #管理帐号
    password=123   #密码
    manager_workdir=/data/mastermha/app1/  #本地工作目录
    manager_log=/data/mastermha/app1/manager.log  #本地的日志
    remote_workdir=/data/mastermha/app1/  #远程工作目录
    ssh_user=root   #SSH帐号
    repl_user=repluser  #复制用帐号
    repl_password=123  #密码
    ping_interval=1  #检测周期

    [server1]  #被管理的节点
    hostname=192.168.8.17   #被管理节点的IP
    candidate_master=1   #可以当主服务器的优先级
    [server2]
    hostname=192.168.8.27
    candidate_master=1
    [server3]
    hostname=192.168.8.37
```

2. 基于key的ssh验证
```bash
#生成密钥
[101]$ ssh-keygen
#复制给自己 
[101]$ ssh-copy-id 192.168.99.101
#看，有这几个文件authorized_keys，id_rsa，id_rsa.pub
[101]$ ls -a .ssh/
.  ..  authorized_keys  id_rsa  id_rsa.pub  known_hosts
#拷贝给其它服务器
[101]$ scp -r .ssh 192.168.99.102:/root/
[101]$ scp -r .ssh 192.168.99.103:/root/
[101]$ scp -r .ssh 192.168.99.104:/root/
#这样就完成了,连接测试下
[101]$ ssh root@192.168.99.102
```

<table><td bgcolor=orange> Master主机：192.168.99.102 </td></table>

1. 修改mariadb配置文件
```bash
[102]$ vim /etc/my.cnf
    [mysqld]
    log-bin
    server_id=1
    skip_name_resolve=1  #忽略名字解析
```

2.  创建连接需要的帐号
```bash
[102]$ mysql

#创建复制用帐号
mysql> grant replication slave on *.* to repluser@'%' identified by '123';
#创建管理用帐号
mysql> grant all on *.* to mhauser@'%'identified by'123';
```

<table><td bgcolor=orange> slave主机：192.168.99.103 </td></table>

1. 修改mariadb配置文件
```bash
[103]$ vim /etc/my.cnf
    [mysqld]
    server_id=2   #不同节点此值各不相同
    log-bin
    read_only
    relay_log_purge=0
    skip_name_resolve=1
```
>这里：关闭`relay_log_purge`是为了不让mysql自动清除中继日志，官方就有这么一句话
>*'Disabling purging of relay logs when using the --relay-log-recovery option risks data consistency and is therefore not crash-safe.'*

2. 连接到主服务器
```bash
[103]$ mysql

MariaDB [(none)]> CHANGE MASTER TO 
MASTER_HOST='192.168.99.102', 
MASTER_PORT=3306,
MASTER_USER='repluser', 
MASTER_PASSWORD='123', 
MASTER_LOG_FILE='mariadb-bin.000001', 
MASTER_LOG_POS=245;

#启动
MariaDB [(none)]> start slave ;
#查看下成功了没
MariaDB [(none)]> show slave status\G;
#看看帐号同步来了没
MariaDB [(none)]> select user from mysql.user;
+----------+
| user     |
+----------+
| mhauser  |
| repluser |
...
```

<table><td bgcolor=orange> 另一个slave主机：192.168.99.104 </td></table>

1. 修改mariadb配置文件
```bash
[104]$ vim /etc/my.cnf
    [mysqld]
    server_id=2   #不同节点此值各不相同
    log-bin
    read_only
    relay_log_purge=0
    skip_name_resolve=1
```

2. 连接到主服务器
```bash
[104]$ mysql

MariaDB [(none)]> CHANGE MASTER TO 
MASTER_HOST='192.168.99.102', 
MASTER_PORT=3306,
MASTER_USER='repluser', 
MASTER_PASSWORD='123', 
MASTER_LOG_FILE='mariadb-bin.000001', 
MASTER_LOG_POS=245;

#启动
MariaDB [(none)]> start slave ;
#查看下成功了没
MariaDB [(none)]> show slave status\G;
#看看帐号同步来了没
MariaDB [(none)]> select user from mysql.user;
+----------+
| user     |
+----------+
| mhauser  |
| repluser |
...
```

<table><td bgcolor=orange> Manager主机：192.168.99.101 </td></table>

1. 检查连接
```bash
[101]$ masterha_check_ssh --conf=/etc/mastermha/app1.cnf
...
Tue Jul 16 09:54:35 2019 - [debug]   ok.
Tue Jul 16 09:54:36 2019 - [info] All SSH connection tests passed successfully.
```

2. 检查复制
```bash
[101]$ masterha_check_repl --conf=/etc/mastermha/app1.cnf
...
MySQL Replication Health is OK.
```

3. 启动，开始监控
```bash
[101]$ masterha_manager --conf=/etc/mastermha/app1.cnf
Tue Jul 16 09:55:10 2019 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.
Tue Jul 16 09:55:10 2019 - [info] Reading application default configuration from /etc/mastermha/app1.cnf..
Tue Jul 16 09:55:10 2019 - [info] Reading server configuration from /etc/mastermha/app1.cnf..
```
Manager的监控是一次性的，当提升完新的主节点后，就完成了使命，程序就自动退出了。


**排错日志：**
`/data/mastermha/app1/manager.log`




- - - 


# 实验：Galera Cluster

1. 实验环境：
3 台主机：192.168.99.101~3


<table><td bgcolor=orange> 主机：192.168.99.101 </td></table>

配置yum源：
```bash
[101]$ vim /etc/yum.repos.d/cdrom.repo
    #还需要一个本地的光盘源，用于安装依赖，这里只显示galera的安装源
    [mariadb]
    name=mariadb
    baseurl=https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.64/yum/centos7-amd64/
    gpgcheck=0
    enabled=1
```
注意：都至少需要三个节点，不能安装mariadb-server

2. 安装MariaDB-Galera-server
```bash
[101]$ yum -y install MariaDB-Galera-server
```

3. 修改配置文件
```bash
[101]$ vim /etc/my.cnf.d/server.cnf
    [galera]
    #程序模块
    wsrep_provider = /usr/lib64/galera/libgalera_smm.so
    wsrep_cluster_address="gcomm://192.168.99.101,192.168.99.102,192.168.99.103"
    binlog_format=row

    #下面默认是注释的，可不动
    default_storage_engine=InnoDB
    innodb_autoinc_lock_mode=2
    bind-address=0.0.0.0

    #下面配置可选项，本实验中没有设置
    wsrep_cluster_name = 'mycluster'  #默认my_wsrep_cluster
    wsrep_node_name = 'node1'
    wsrep_node_address = '192.168.8.7'
```

4. 各个主机上的配置文件都一样，所以这里就直接拷贝到其它主机上
```bash
[101]$ scp /etc/my.cnf.d/server.cnf 192.168.99.102:/etc/my.cnf.d/

[101]$ scp /etc/my.cnf.d/server.cnf 192.168.99.103:/etc/my.cnf.d/
```

5. 首次启动时，需要初始化集群，在其中一个节点上执行命令
```bash
[101]$ /etc/init.d/mysql start --wsrep-new-cluster
```

<table><td bgcolor=orange> 主机：192.168.99.102 </td></table>

1. 正常启动其它节点
```bash
[102]$ service mysql start
```

<table><td bgcolor=orange> 主机：192.168.99.103 </td></table>

1. 正常启动其它节点
```bash
[103]$ service mysql start
```
这样就完成了。

**查看集群中相关系统变量和状态变量**
```bash
#查看系统变量
SHOW VARIABLES LIKE 'wsrep_%';
#查看状态变量
SHOW STATUS LIKE 'wsrep_%';
#查看有几个节点，配置正常应该为3
SHOW STATUS LIKE 'wsrep_cluster_size';
```