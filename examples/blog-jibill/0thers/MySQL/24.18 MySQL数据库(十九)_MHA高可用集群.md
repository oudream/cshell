[toc]

# MySQL高可用
**MMM**
>MMM: Multi-Master Replication Manager for MySQL，Mysql主主复制管理器是一套灵活的脚本程序，基于perl实现，用来对mysql replication进行监控和故障迁移，并能管理mysql Master-Master复制的配置(同一时间只有一个节点是可写的)
>>官网： http://www.mysql-mmm.org
https://code.google.com/archive/p/mysql-master-master/downloads

**MHA**
>MHA：Master High Availability，对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现，目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，出于机器成本的考虑，淘宝进行了改造，目前淘宝TMHA已经支持一主一从
>>官网:https://code.google.com/archive/p/mysql-master-ha/

**Galera Cluster**
>Galera Cluster：wsrep(MySQL extended with the Write Set Replication)
通过wsrep协议在全局实现复制；任何一节点都可读写，不需要主从复制，实现多主读写

**GR**
>GR（Group Replication）：MySQL官方提供的组复制技术(MySQL 5.7.17引入的技术)，基于原生复制技术Paxos算法


# MHA集群架构
![在这里插入图片描述](https://img-blog.csdnimg.cn/2019071608591665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aHNvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)


## MHA工作原理
1. 从宕机崩溃的master保存二进制日志事件（binlog events）
2. 识别含有最新更新的slave
3. 应用差异的中继日志（relay log）到其他的slave
4. 应用从master保存的二进制日志事件（binlog events）
5. 提升一个slave为新的master
6. 使其他的slave连接新的master进行复制


## Manager工具包
MHA软件由两部分组成，Manager工具包和Node工具包

+ **Manager工具; 包主要包括以下几个工具：**
    `masterha_check_ssh` 检查MHA的SSH配置状况
    `masterha_check_repl` 检查MySQL复制状况
    `masterha_manger` 启动MHA
    `masterha_check_status` 检测当前MHA运行状态
    `masterha_master_monitor` 检测master是否宕机
    `masterha_master_switch` 故障转移（自动或手动）
    `masterha_conf_host` 添加或删除配置的server信息


+ **Node工具包：** 这些工具通常由MHA Manager的脚本触发，无需人为操作,主要包括以下几个工具：
    `save_binary_logs` 保存和复制master的二进制日志
    `apply_diff_relay_logs` 识别差异的中继日志事件并将其差异的事件应用于其他的slave
    `filter_mysqlbinlog` 去除不必要的ROLLBACK事件（MHA已不再使用此工具）
    `purge_relay_logs` 清除中继日志（不会阻塞SQL线程）

注意：为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议配置成MySQL 5.5的半同步复制



+ 自定义扩展：
    `secondary_check_script`： 通过多条网络路由检测master的可用性
    `master_ip_ailover_script`： 更新Application使用的masterip
    `shutdown_script`： 强制关闭master节点
    `report_script`： 发送报告
    `init_conf_load_script`： 加载初始配置参数
    `master_ip_online_change_script`：更新master节点ip地址

+ 配置文件：
`global`配置，为各application提供默认配置
`application`配置：为每个主从复制集群


实验：[MySQL数据库_MySQL高可用集群实验](https://thson.blog.csdn.net/article/details/96114601)


# Galera Cluster
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190706160554374.png)

> Galera Cluster：集成了Galera插件的MySQL集群，是一种新型的，数据不共享的，高度冗余的高可用方案，目前Galera Cluster有两个版本，分别是Percona Xtradb Cluster及MariaDB Cluster，Galera本身是具有多主特性的，即采用multi-master的集群架构，是一个既稳健，又在数据一致性、完整性及高性能方面有出色表现的高可用解决方案
>
>上图图示：三个节点组成了一个集群，与普通的主从架构不同，它们都可以作为主节点，三个节点是对等的，称为multi-master架构，当有客户端要写入或者读取数据时，连接哪个实例都是一样的，读到的数据是相同的，写入某一个节点之后，集群自己会将新数据同步到其它节点上面，这种架构不共享任何数据，是一种高冗余架构
>
>Galera Cluster官方文档：
http://galeracluster.com/documentation-webpages/galera-documentation.pdf
http://galeracluster.com/documentation-webpages/index.html
https://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/

## Galera Cluster特点
1. **多主架构**：真正的多点读写的集群，在任何时候读写数据，都是最新的
2. **同步复制**：集群不同节点之间数据同步，没有延迟，在数据库挂掉之后，数据不会丢失
3. **并发复制**：从节点APPLY数据时，支持并行执行，更好的性能
4. **故障切换**：在出现数据库故障时，因支持多点写入，切换容易
5. **热插拔**：在服务期间，如果数据库挂了，只要监控程序发现的够快，不可服务时间就会非常少。在节点故障期间，节点本身对集群的影响非常小
6. **自动节点克隆**：在新增节点，或者停机维护时，增量数据或者基础数据不需要人工手动备份提供，Galera Cluster会自动拉取在线节点数据，最终集群会变为一致
7. **对应用透明**：集群的维护，对应用程序是透明的

**Galera Cluster工作过程**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190706160609635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly90aHNvbi5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)



## Galera Cluster包括两个组件
1. Galera replication library (galera-3)
2. WSREP：MySQL extended with the Write Set Replication


### WSREP复制实现：
`PXC`：Percona XtraDB Cluster，是Percona对Galera的实现

> MariaDB Galera Cluster
> 参考仓库：https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.X/yum/centos7-amd64/
注意：都至少需要三个节点，不能安装mariadb-server

实验：[MySQL数据库_MySQL高可用集群实验](https://thson.blog.csdn.net/article/details/96114601)


### 复制的问题和解决方案：
(1) 数据损坏或丢失
`Master`： MHA + semi repl
`Slave`： 重新复制
(2) 混合使用存储引擎
`MyISAM`：不支持事务
`InnoDB`： 支持事务
(3) 不唯一的server id
重新复制
(4) 复制延迟
需要额外的监控工具的辅助
一从多主：mariadb10版后支持
多线程复制：对多个数据库复制


# TiDb概述
> TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。 tidb和mysql几乎完全兼容
>
>TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。
>
>TiDB 的目标是为 OLTP(Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。


## TiDB 具备如下核心特点
1. 高度兼容 MySQL 大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移
2. 水平弹性扩展 通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。
3. 分布式事务 TiDB 100% 支持标准的 ACID 事务
4. 真正金融级高可用 相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。
5. 一站式 HTAP 解决方案 TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP解决方案，一份存储同时处理OLTP & OLAP(OLAP、OLTP的介绍和比较 )无需传统繁琐的 ETL 过程。
6. 云原生 SQL 数据库 TiDB 是为云而设计的数据库，同 Kubernetes （十分钟带你理解Kubernetes核心概念 ）深度耦合，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。 TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。 
7. TiDB 对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力.  


