#!/usr/bin/env bash

file * | grep " x " | sort -t ',' -k 2 -n

### sort
# sort的工作原理
# sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。
# -u: 它的作用很简单，就是在输出行中去除重复行
# -r: sort默认的排序方式是升序，如果想改成降序，就加个-r就搞定了。
# -o: sort -r number.txt -o number.txt 把结果写入到原文件中。如果写新文件直接用重定向可就行了。
# -n: 要以数值来排序
# -t: 设定间隔符。sort -n -k 2 -t : facebook.txt
# -f: 会将小写字母都转换为大写字母来进行比较，亦即忽略大小写
# -c: 会检查文件是否已排好序，如果乱序，则输出第一个乱序的行的相关信息，最后返回1
# -C: 会检查文件是否已排好序，如果乱序，不输出内容，仅返回1
# -M: 会以月份来排序，比如JAN小于FEB等等
# -b: 会忽略每一行前面的所有空白部分，从第一个可见字符开始比较。
# -k: ***重点***. sort -t ‘ ‘ -k 1 facebook.txt 按第一个域进行排序
# -k: sort -n -t ‘ ‘ -k 3r -k 2 facebook.txt 按第三个域进行降序排序
# -k选项的具体语法格式
# 要继续往下深入的话，就不得不来点理论知识。你需要了解-k选项的语法格式，如下：
# [ FStart [ .CStart ] ] [ Modifier ] [ , [ FEnd [ .CEnd ] ][ Modifier ] ]
# 这个语法格式可以被其中的逗号（“，”）分为两大部分，Start部分和End部分。
# 先给你灌输一个思想，那就是“如果不设定End部分，那么就认为End被设定为行尾”。这个概念很重要的，但往往你不会重视它。
# Start部分也由三部分组成，其中的Modifier部分就是我们之前说过的类似n和r的选项部分。我们重点说说Start部分的FStart和C.Start。
# C.Start也是可以省略的，省略的话就表示从本域的开头部分开始。之前例子中的-k 2和-k 3就是省略了C.Start的例子喽。
# FStart.CStart，其中FStart就是表示使用的域，而CStart则表示在FStart域中从第几个字符开始算“排序首字符”。
# 同理，在End部分中，你可以设定FEnd.CEnd，如果你省略.CEnd，则表示结尾到“域尾”，即本域的最后一个字符。或者，如果你将CEnd设定为0(零)，也是表示结尾到“域尾”。
sort -t ' ' -k 1.2 facebook.txt # 第二个字母开始进行排序
sort -t ' ' -k 1.2,1.2 -k 3,3nr facebook.txt # 第二个字母进行排序，如果相同的按照员工工资进行降序排序


# uniq 命令用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用。
# uniq 可检查文本文件中重复出现的行列。

uniq [-cdu][-f<栏位>][-s<字符位置>][-w<字符位置>][--help][--version][输入文件][输出文件]

## 参数：
# -c或--count 在每列旁边显示该行重复出现的次数。
# -d或--repeated 仅显示重复出现的行列。
# -f<栏位>或--skip-fields=<栏位> 忽略比较指定的栏位。
# -s<字符位置>或--skip-chars=<字符位置> 忽略比较指定的字符。
# -u或--unique 仅显示出一次的行列。
# -w<字符位置>或--check-chars=<字符位置> 指定要比较的字符。
# --help 显示帮助。
# --version 显示版本信息。
# [输入文件] 指定已排序好的文本文件。如果不指定此项，则从标准读取数据；
# [输出文件] 指定输出的文件。如果不指定此选项，则将内容显示到标准输出设备（显示终端）。
# 实例
# 文件testfile中第 2、3、5、6、7、9行为相同的行，使用 uniq 命令删除重复的行，可使用以下命令：
#
# uniq testfile
# testfile中的原有内容为：
#
cat testfile      #原有内容
# test 30
# test 30
# test 30
# Hello 95
# Hello 95
# Hello 95
# Hello 95
# Linux 85
# Linux 85
# 使用uniq 命令删除重复的行后，有如下输出结果：
#
uniq testfile     #删除重复行后的内容
# test 30
# Hello 95
# Linux 85
# 检查文件并删除文件中重复出现的行，并在行首显示该行重复出现的次数。使用如下命令：
#
# uniq -c testfile
# 结果输出如下：
#
uniq -c testfile      #删除重复行后的内容
# 3 test 30             #前面的数字的意义为该行共出现了3次
# 4 Hello 95            #前面的数字的意义为该行共出现了4次
# 2 Linux 85            #前面的数字的意义为该行共出现了2次
# 当重复的行并不相邻时，uniq 命令是不起作用的，即若文件内容为以下时，uniq 命令不起作用：